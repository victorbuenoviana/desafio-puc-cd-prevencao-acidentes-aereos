{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocorr = pd.read_csv(r'..\\data\\df_ocorrencias_aeronauticas_tratado.csv')\n",
    "df_ocorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo uma função para normalizar as strings\n",
    "def normalizar_string(string):\n",
    "\n",
    "    string_normalizada = string.strip() # remove espaços em branco no início e no final da string\n",
    "    string_normalizada = string_normalizada.lower() # transforma todas as letras em minúsculas\n",
    "    string_normalizada = unidecode.unidecode(string_normalizada)\n",
    "    string_normalizada = re.sub(r'[^\\w\\s-]', '', string_normalizada)\n",
    "\n",
    "    return string_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo os tipos de dados de cada coluna\n",
    "df_ocorr[\"ocorrencia_latitude\"] = df_ocorr[\"ocorrencia_latitude\"].apply(lambda x: \".\".join(str(x).split(\".\")[0:2]).replace(\"°\",\"\")).astype(float)        \n",
    "df_ocorr[\"ocorrencia_longitude\"] = df_ocorr[\"ocorrencia_longitude\"].apply(lambda x: \".\".join(str(x).split(\".\")[0:2]).replace(\"°\",\"\")).astype(float)  \n",
    "df_ocorr[\"ocorrencia_classificacao\"] = df_ocorr[\"ocorrencia_classificacao\"].apply(normalizar_string).astype(\"category\")              \n",
    "df_ocorr[\"ocorrencia_cidade\"] = df_ocorr[\"ocorrencia_cidade\"].apply(normalizar_string).astype(\"category\")        \n",
    "df_ocorr[\"ocorrencia_uf\"] = df_ocorr[\"ocorrencia_uf\"].apply(normalizar_string).astype(\"category\")                        \n",
    "df_ocorr[\"ocorrencia_aerodromo\"] = df_ocorr[\"ocorrencia_aerodromo\"].apply(lambda x: x.strip().lower()).astype(\"category\")           \n",
    "df_ocorr[\"total_recomendacoes\"] = df_ocorr[\"total_recomendacoes\"].astype(int)            \n",
    "df_ocorr[\"total_aeronaves_envolvidas\"] = df_ocorr[\"total_aeronaves_envolvidas\"].astype(int)     \n",
    "df_ocorr[\"ocorrencia_saida_pista\"] = df_ocorr[\"ocorrencia_saida_pista\"].apply(lambda x: x.strip().lower()).astype(\"category\")         \n",
    "df_ocorr[\"ocorrencia_tipo\"] = df_ocorr[\"ocorrencia_tipo\"].apply(normalizar_string).astype(\"category\")            \n",
    "df_ocorr[\"ocorrencia_tipo_categoria\"] = df_ocorr[\"ocorrencia_tipo_categoria\"].apply(normalizar_string).astype(\"category\")      \n",
    "df_ocorr[\"taxonomia_tipo_icao\"] = df_ocorr[\"taxonomia_tipo_icao\"].apply(lambda x: x.strip()).astype(\"category\")        \n",
    "df_ocorr[\"recomendacao_status\"] = df_ocorr[\"recomendacao_status\"].apply(lambda x: x.strip().lower()).astype(\"category\")            \n",
    "df_ocorr[\"recomendacao_destinatario\"] = df_ocorr[\"recomendacao_destinatario\"].apply(lambda x: x.strip().lower()).astype(\"category\")                \n",
    "df_ocorr[\"aeronave_tipo_veiculo\"] = df_ocorr[\"aeronave_tipo_veiculo\"].apply(normalizar_string).astype(\"category\")          \n",
    "df_ocorr[\"aeronave_fabricante\"] = df_ocorr[\"aeronave_fabricante\"].apply(normalizar_string).astype(\"category\")            \n",
    "df_ocorr[\"aeronave_modelo\"] = df_ocorr[\"aeronave_modelo\"].apply(lambda x: x.strip().lower()).astype(\"category\")                        \n",
    "df_ocorr[\"aeronave_motor_tipo\"] = df_ocorr[\"aeronave_motor_tipo\"].apply(normalizar_string).astype(\"category\")            \n",
    "df_ocorr[\"aeronave_motor_quantidade\"] = df_ocorr[\"aeronave_motor_quantidade\"].apply(normalizar_string).astype(\"category\")       \n",
    "df_ocorr[\"aeronave_voo_origem\"] = df_ocorr[\"aeronave_voo_origem\"].apply(lambda x: x.strip().lower()).astype(str).astype(\"category\")             \n",
    "df_ocorr[\"aeronave_voo_destino\"] = df_ocorr[\"aeronave_voo_destino\"].apply(lambda x: x.strip().lower()).astype(str).astype(\"category\")            \n",
    "df_ocorr[\"aeronave_fase_operacao\"] = df_ocorr[\"aeronave_fase_operacao\"].apply(normalizar_string).astype(\"category\")         \n",
    "df_ocorr[\"aeronave_tipo_operacao\"] = df_ocorr[\"aeronave_tipo_operacao\"].apply(normalizar_string).astype(\"category\")         \n",
    "df_ocorr[\"aeronave_nivel_dano\"] = df_ocorr[\"aeronave_nivel_dano\"].apply(normalizar_string).astype(\"category\")            \n",
    "df_ocorr[\"aeronave_fatalidades_total\"] = df_ocorr[\"aeronave_fatalidades_total\"].astype(int)      \n",
    "df_ocorr[\"fator_nome\"] = df_ocorr[\"fator_nome\"].apply(normalizar_string).astype(\"category\")                    \n",
    "df_ocorr[\"fator_aspecto\"] = df_ocorr[\"fator_aspecto\"].apply(normalizar_string).astype(\"category\")                  \n",
    "df_ocorr[\"fator_condicionante\"] = df_ocorr[\"fator_condicionante\"].apply(normalizar_string).astype(\"category\")            \n",
    "df_ocorr[\"fator_area\"] = df_ocorr[\"fator_area\"].apply(normalizar_string).astype(\"category\")\n",
    "df_ocorr[\"ocorrencia_data_hora\"] = pd.to_datetime(df_ocorr[\"ocorrencia_data_hora\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo condição de junção dos dados meteorologicos e de ocorrências aeronáuticas\n",
    "df_ocorr[\"condicao\"] = list(zip(df_ocorr[\"ocorrencia_cidade\"], df_ocorr[\"ocorrencia_data_hora\"].dt.date, df_ocorr[\"ocorrencia_data_hora\"].dt.hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associando dados Meteorológicos aos dados de Ocorrências Aeronáuticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo condição de junção dos dados meteorologicos e de ocorrências aeronáuticas\n",
    "df_ocorr[\"condicao\"] = list(zip(df_ocorr[\"ocorrencia_cidade\"], df_ocorr[\"ocorrencia_data_hora\"].dt.date, df_ocorr[\"ocorrencia_data_hora\"].dt.hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listando paths dos arquivos com dados meteorológicos\n",
    "path_root_meteor = r'..\\data\\dados-meteorologicos'\n",
    "\n",
    "list_dirs = os.listdir(path_root_meteor)\n",
    "\n",
    "list_paths_dirs_meteor = []\n",
    "list_path_files_meteor = []\n",
    "\n",
    "for ano_dir in list_dirs:\n",
    "\n",
    "    list_paths_dirs_meteor.append(os.path.join(path_root_meteor, ano_dir))\n",
    "\n",
    "for path_dir in list_paths_dirs_meteor:\n",
    "\n",
    "    list_files = os.listdir(path_dir)\n",
    "\n",
    "    for file in list_files:\n",
    "        \n",
    "        list_path_files_meteor.append(os.path.join(path_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dados_meteor_sem_cabecalho = r'..\\data\\dados-meteorologicos-sem-cabecalho'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo cabeçalho dos arquivos de dados meteorológicos e padronizando o encoding com utf8\n",
    "for path in list_path_files_meteor:\n",
    "\n",
    "    path_arquivo_dados_meteorologicos_sem_cabecalho =  os.path.join(path_dados_meteor_sem_cabecalho, path.split(\"\\\\\")[-1])\n",
    "\n",
    "    # identificando encoding do arquivo\n",
    "    with open(path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "\n",
    "    result = chardet.detect(raw_data)\n",
    "    encoding = result['encoding']\n",
    "\n",
    "    # Abrindo o arquivo original e o novo arquivo em modo de escrita\n",
    "    with open(path, 'r', encoding=encoding) as file, open(path_arquivo_dados_meteorologicos_sem_cabecalho, 'w', newline='',encoding='utf8') as path_arquivo_dados_meteorologicos_sem_cabecalho:\n",
    "\n",
    "        # Cria um objeto csv.reader para ler o arquivo original\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        # Cria um objeto csv.writer para escrever no arquivo de destino\n",
    "        writer = csv.writer(path_arquivo_dados_meteorologicos_sem_cabecalho)\n",
    "\n",
    "        # Ignora as primeiras 8 linhas\n",
    "        for _ in range(8):\n",
    "            next(reader)\n",
    "\n",
    "        # Copia as linhas restantes para o arquivo de destino\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associando dados meteorológicos aos dados de ocorrências aeronáuticas\n",
    "\n",
    "# criando coluna com a condição de junção dos dados meteorologicos e de ocorrências aeronáuticas no df_ocorr \n",
    "df_ocorr[\"condicao\"] = list(zip(df_ocorr[\"ocorrencia_cidade\"], df_ocorr[\"ocorrencia_data_hora\"].dt.date, df_ocorr[\"ocorrencia_data_hora\"].dt.hour))\n",
    "\n",
    "lista_falhas = []\n",
    "\n",
    "for file in os.listdir(path_dados_meteor_sem_cabecalho):\n",
    "\n",
    "    path = os.path.join(path_dados_meteor_sem_cabecalho, file)\n",
    "\n",
    "    #obtendo nome da cidade\n",
    "    nome_arquivo = path.split(sep=\"\\\\\")[-1]\n",
    "    nome_cidade = nome_arquivo.split(sep=\"_\")[4]\n",
    "    nome_cidade = normalizar_string(nome_cidade)\n",
    "\n",
    "    df_arquivo = pd.read_csv(path, sep=';', encoding='utf8')\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # filtrando colunas de interesse\n",
    "        df_arquivo = df_arquivo[['DATA (YYYY-MM-DD)', 'HORA (UTC)', 'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)','PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)','RADIACAO GLOBAL (KJ/m²)','TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)','TEMPERATURA DO PONTO DE ORVALHO (°C)','UMIDADE RELATIVA DO AR, HORARIA (%)','VENTO, DIREÇÃO HORARIA (gr) (° (gr))', 'VENTO, RAJADA MAXIMA (m/s)','VENTO, VELOCIDADE HORARIA (m/s)']]\n",
    "\n",
    "        # unindo data e hora\n",
    "        df_arquivo['data_hora'] = df_arquivo['DATA (YYYY-MM-DD)'] + ' ' + df_arquivo['HORA (UTC)']\n",
    "        df_arquivo['data_hora'] = pd.to_datetime(df_arquivo['data_hora'], format='%Y-%m-%d %H:%M')\n",
    "        df_arquivo.drop('DATA (YYYY-MM-DD)', axis=1, inplace=True)\n",
    "        df_arquivo.drop('HORA (UTC)', axis=1, inplace=True)\n",
    "\n",
    "        # renomeando as colunas do dataframe\n",
    "        df_arquivo.columns = ['precip_total_horario[mm]','pres_atm_estacao_horaria[mB]','radiacao_global[KJ/m2]','temp_ar_bulbo_seco_horario[oC]','temp_ponto_orvalho[oC]','umid_relat_ar_hora_atual[%]','vento_direcao_hora[gr]','vento_rajada_max_hora[m/s]','vento_vel_hora[m/s]','data_hora']\n",
    "\n",
    "        # tratando tipos de dados\n",
    "        df_arquivo['precip_total_horario[mm]'] = df_arquivo['precip_total_horario[mm]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['pres_atm_estacao_horaria[mB]'] = df_arquivo['pres_atm_estacao_horaria[mB]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['radiacao_global[KJ/m2]'] = df_arquivo['radiacao_global[KJ/m2]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['temp_ar_bulbo_seco_horario[oC]'] = df_arquivo['temp_ar_bulbo_seco_horario[oC]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['temp_ponto_orvalho[oC]'] = df_arquivo['temp_ponto_orvalho[oC]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['umid_relat_ar_hora_atual[%]'] = df_arquivo['umid_relat_ar_hora_atual[%]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['vento_direcao_hora[gr]'] = df_arquivo['vento_direcao_hora[gr]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['vento_rajada_max_hora[m/s]'] = df_arquivo['vento_rajada_max_hora[m/s]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['vento_vel_hora[m/s]'] = df_arquivo['vento_vel_hora[m/s]'].apply(lambda x: str(x).replace(\",\",\".\").replace(\" \", \"\")).astype(float)\n",
    "        df_arquivo['data_hora'] = pd.to_datetime(df_arquivo['data_hora'])\n",
    "\n",
    "        # tratando valores inválidos\n",
    "        df_arquivo.loc[df_arquivo['precip_total_horario[mm]'] == -9999.0,'precip_total_horario[mm]'] = 0\n",
    "        df_arquivo.loc[df_arquivo['pres_atm_estacao_horaria[mB]'] == -9999.0, 'pres_atm_estacao_horaria[mB]'] = df_arquivo['pres_atm_estacao_horaria[mB]'].median()\n",
    "        df_arquivo.loc[df_arquivo['pres_atm_estacao_horaria[mB]'] == 0, 'pres_atm_estacao_horaria[mB]'] = df_arquivo['pres_atm_estacao_horaria[mB]'].median()\n",
    "        df_arquivo.loc[df_arquivo['radiacao_global[KJ/m2]'] == -9999.0, 'radiacao_global[KJ/m2]'] = df_arquivo['radiacao_global[KJ/m2]'].median()\n",
    "        df_arquivo.loc[df_arquivo['radiacao_global[KJ/m2]'] == 0,'radiacao_global[KJ/m2]'] = df_arquivo['radiacao_global[KJ/m2]'].median()\n",
    "        df_arquivo.loc[df_arquivo['temp_ar_bulbo_seco_horario[oC]'] == -3698.838209, 'temp_ar_bulbo_seco_horario[oC]'] = df_arquivo['temp_ar_bulbo_seco_horario[oC]'].median()\n",
    "        df_arquivo.loc[df_arquivo['temp_ar_bulbo_seco_horario[oC]'] == -9999.0, 'temp_ar_bulbo_seco_horario[oC]'] = df_arquivo['temp_ar_bulbo_seco_horario[oC]'].median()\n",
    "        df_arquivo.loc[df_arquivo['temp_ar_bulbo_seco_horario[oC]'] == 858.794509, 'temp_ar_bulbo_seco_horario[oC]'] = df_arquivo['temp_ar_bulbo_seco_horario[oC]'].median()\n",
    "        df_arquivo.loc[df_arquivo['temp_ar_bulbo_seco_horario[oC]'] == 0, 'temp_ar_bulbo_seco_horario[oC]'] = df_arquivo['temp_ar_bulbo_seco_horario[oC]'].median()\n",
    "        df_arquivo.loc[df_arquivo['temp_ponto_orvalho[oC]'] == -3698.838209, 'temp_ponto_orvalho[oC]'] = df_arquivo['temp_ponto_orvalho[oC]'].median()\n",
    "        df_arquivo.loc[df_arquivo['temp_ponto_orvalho[oC]'] == -9999.0, 'temp_ponto_orvalho[oC]'] = df_arquivo['temp_ponto_orvalho[oC]'].median()\n",
    "        df_arquivo.loc[df_arquivo['temp_ponto_orvalho[oC]'] == 858.794509, 'temp_ponto_orvalho[oC]'] = df_arquivo['temp_ponto_orvalho[oC]'].median()\n",
    "        df_arquivo.loc[df_arquivo['umid_relat_ar_hora_atual[%]'] == -3698.838209, 'umid_relat_ar_hora_atual[%]'] = df_arquivo['umid_relat_ar_hora_atual[%]'].median()\n",
    "        df_arquivo.loc[df_arquivo['umid_relat_ar_hora_atual[%]'] == -9999.0, 'umid_relat_ar_hora_atual[%]'] = df_arquivo['umid_relat_ar_hora_atual[%]'].median()\n",
    "        df_arquivo.loc[df_arquivo['umid_relat_ar_hora_atual[%]'] == 858.794509, 'umid_relat_ar_hora_atual[%]'] = df_arquivo['umid_relat_ar_hora_atual[%]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_direcao_hora[gr]'] == -3698.838209, 'vento_direcao_hora[gr]'] = df_arquivo['vento_direcao_hora[gr]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_direcao_hora[gr]'] == -9999.0, 'vento_direcao_hora[gr]'] = df_arquivo['vento_direcao_hora[gr]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_direcao_hora[gr]'] == 858.794509, 'vento_direcao_hora[gr]'] = df_arquivo['vento_direcao_hora[gr]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_rajada_max_hora[m/s]'] == -3698.838209, 'vento_rajada_max_hora[m/s]'] = df_arquivo['vento_rajada_max_hora[m/s]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_rajada_max_hora[m/s]'] == -9999.0, 'vento_rajada_max_hora[m/s]'] = df_arquivo['vento_rajada_max_hora[m/s]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_rajada_max_hora[m/s]'] == 858.794509, 'vento_rajada_max_hora[m/s]'] = df_arquivo['vento_rajada_max_hora[m/s]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_vel_hora[m/s]'] == -9999.0, 'vento_vel_hora[m/s]'] = df_arquivo['vento_vel_hora[m/s]'].median()\n",
    "        df_arquivo.loc[df_arquivo['vento_vel_hora[m/s]'] == 858.794509, 'vento_vel_hora[m/s]'] = df_arquivo['vento_vel_hora[m/s]'].median()\n",
    "        \n",
    "        # removendo linhas duplicadas\n",
    "        df_arquivo = df_arquivo.drop_duplicates()\n",
    "\n",
    "        # criando coluna com a condição de junção dos dados meteorologicos e de ocorrências aeronáuticas no df_arquivo\n",
    "        df_arquivo[\"cidade\"] = nome_cidade\n",
    "        df_arquivo[\"condicao\"] = list(zip(df_arquivo[\"cidade\"], df_arquivo[\"data_hora\"].dt.date, df_arquivo[\"data_hora\"].dt.hour))\n",
    "        df_arquivo = df_arquivo.drop(\"cidade\", axis=1)\n",
    "   \n",
    "        # associando dados meteorológicos aos dados de ocorrências aeronáuticas \n",
    "        df_ocorr = pd.merge(df_ocorr, df_arquivo, on=\"condicao\", how=\"left\")\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        import inspect\n",
    "        lista_falhas.append(f\"{inspect.getframeinfo(inspect.currentframe()).function};{e};{file}\")\n",
    "\n",
    "    finally:\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando lista de arquivos não adicionados à base de dados consolidada, para análise posterior\n",
    "pd.DataFrame(lista_falhas).to_csv(r\"..\\data\\lista_falhas_merge.csv\",index=False, header=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando base de dados integrada\n",
    "df_ocorr.to_csv(r\"..\\data\\arquivos_nao_consolidados.csv\",index=False, header=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
