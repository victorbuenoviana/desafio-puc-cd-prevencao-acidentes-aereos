{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalando módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install csv\n",
    "# ! pip install pandas\n",
    "# ! pip install chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importanto Módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_arquivos_originais(path_root_dir: str):\n",
    "    \n",
    "    list_dirs = os.listdir(path_root_dir)\n",
    "\n",
    "    list_paths_dirs = []\n",
    "    list_path_files = []\n",
    "\n",
    "    for ano_dir in list_dirs:\n",
    "\n",
    "        list_paths_dirs.append(os.path.join(path_root_dir, ano_dir))\n",
    "\n",
    "    for path_dir in list_paths_dirs:\n",
    "\n",
    "        list_files = os.listdir(path_dir)\n",
    "\n",
    "        for file in list_files:\n",
    "\n",
    "            list_path_files.append(os.path.join(path_dir, file))\n",
    "    \n",
    "    return list_path_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identificar_encoding(path_file: str):\n",
    "    with open(path_file, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "\n",
    "    result = chardet.detect(raw_data)\n",
    "    encoding = result['encoding']\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_dados_geograficos_estacao(path_file: str):\n",
    "\n",
    "    with open(path_file, mode='r') as file:\n",
    "        \n",
    "        csv_reader = csv.reader(file)\n",
    "        lines = list(csv_reader)\n",
    "\n",
    "    lines = lines[:8]\n",
    "    \n",
    "    try:\n",
    "        dados_estacao = {\n",
    "        'regiao' : lines[0][0].split(';')[1],\n",
    "        'uf' : lines[1][0].split(';')[1],\n",
    "        'estacao' : lines[2][0].split(';')[1],\n",
    "        'latitude' : lines[4][0].split(';')[1]+'.'+lines[4][1],\n",
    "        'longitude' : lines[5][0].split(';')[1]+'.'+lines[5][1],\n",
    "        'altitude' : lines[6][0].split(';')[1],\n",
    "        }\n",
    "        return dados_estacao\n",
    "    \n",
    "    except Exception as e:\n",
    "     \n",
    "        import inspect\n",
    "        print(f\"{inspect.getframeinfo(inspect.currentframe()).function};{e};{path_file}\")\n",
    "\n",
    "    finally:\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_dados_meteorologicos(path_file: str):\n",
    "\n",
    "    path_dir_destino_dados_meteorologicos = r'..\\data\\dados_tratados\\dados_meteorologicos_separados'\n",
    "    path_arquivo_dados_meteorologicos =  os.path.join(path_dir_destino_dados_meteorologicos, path_file.split(\"\\\\\")[-1])\n",
    "\n",
    "    # Abrindo o arquivo original e o novo arquivo em modo de escrita\n",
    "    with open(path_file, 'r') as file, open(path_arquivo_dados_meteorologicos, 'w', newline='') as path_arquivo_dados_meteorologicos:\n",
    "\n",
    "        # Cria um objeto csv.reader para ler o arquivo original\n",
    "        reader = csv.reader(file)\n",
    "        # Cria um objeto csv.writer para escrever no arquivo de destino\n",
    "        writer = csv.writer(path_arquivo_dados_meteorologicos)\n",
    "\n",
    "        # Ignora as primeiras 8 linhas\n",
    "        for _ in range(8):\n",
    "            next(reader)\n",
    "\n",
    "        # Copia as linhas restantes para o arquivo de destino\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_dados_meteorologicos(path_arquivo_dados_meteorologicos: str, encoding: str):\n",
    "\n",
    "    df = pd.read_csv(path_arquivo_dados_meteorologicos, sep=';', encoding=encoding)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        df['data_hora'] = df['DATA (YYYY-MM-DD)'] + ' ' + df['HORA (UTC)']\n",
    "        df['data_hora'] = pd.to_datetime(df['data_hora'], format='%Y-%m-%d %H:%M')\n",
    "        df.drop('Unnamed: 19', axis=1, inplace=True)\n",
    "        df.drop('DATA (YYYY-MM-DD)', axis=1, inplace=True)\n",
    "        df.drop('HORA (UTC)', axis=1, inplace=True)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        import inspect\n",
    "        print(f\"{inspect.getframeinfo(inspect.currentframe()).function};{e};{path_arquivo_dados_meteorologicos}\")\n",
    "\n",
    "    finally:\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrar_dados_geograficos_meteorologicos(dados_meteorologicos: pd.DataFrame, dados_geograficos: dict):\n",
    "\n",
    "    df = dados_meteorologicos\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        for chave_valor in dados_geograficos.items():\n",
    "\n",
    "            dados_meteorologicos[f'{chave_valor[0]}'] = f'{chave_valor[1]}'\n",
    "            \n",
    "        # renomeando as colunas do dataframe\n",
    "        df.columns = [\n",
    "            'precip_total_horario[mm]',\n",
    "            'pres_atm_estacao_horaria[mB]',\n",
    "            'pres_atm_max_hora_ant[mB]',\n",
    "            'pres_atm_min_hora_ant[mB]',\n",
    "            'radiacao_global[KJ/m2]',\n",
    "            'temp_ar_bulbo_seco_horario[oC]',\n",
    "            'temp_ponto_orvalho[oC]',\n",
    "            'temp_max_hora_ant[oC]',\n",
    "            'temp_min_hora_ant[oC]',\n",
    "            'temp_orv_max_hora_ant[oC]',\n",
    "            'temp_orv_min_hora_ant[oC]',\n",
    "            'umid_relat_ar_max_hora_ant[%]',\n",
    "            'umid_relat_ar_min_hora_ant[%]',\n",
    "            'umid_relat_ar_hora_atual[%]',\n",
    "            'vento_direcao_hora[gr]',\n",
    "            'vento_rajada_max_hora[m/s]',\n",
    "            'vento_vel_hora[m/s]',\n",
    "            'data_hora',\n",
    "            'regiao', \n",
    "            'uf',\n",
    "            'estacao_cidade', \n",
    "            'estacao_latitude', \n",
    "            'estacao_longitude', \n",
    "            'estacao_altitude',\n",
    "            ]\n",
    "        \n",
    "        # reordenando as colunas do dataframe\n",
    "        df = df.reindex(columns=[\n",
    "            'data_hora',\n",
    "            'estacao_cidade', \n",
    "            'uf',\n",
    "            'regiao', \n",
    "            'estacao_latitude', \n",
    "            'estacao_longitude', \n",
    "            'estacao_altitude',\n",
    "            'precip_total_horario[mm]',\n",
    "            'pres_atm_estacao_horaria[mB]',\n",
    "            'pres_atm_max_hora_ant[mB]',\n",
    "            'pres_atm_min_hora_ant[mB]',\n",
    "            'radiacao_global[KJ/m2]',\n",
    "            'temp_ar_bulbo_seco_horario[oC]',\n",
    "            'temp_ponto_orvalho[oC]',\n",
    "            'temp_max_hora_ant[oC]',\n",
    "            'temp_min_hora_ant[oC]',\n",
    "            'temp_orv_max_hora_ant[oC]',\n",
    "            'temp_orv_min_hora_ant[oC]',\n",
    "            'umid_relat_ar_max_hora_ant[%]',\n",
    "            'umid_relat_ar_min_hora_ant[%]',\n",
    "            'umid_relat_ar_hora_atual[%]',\n",
    "            'vento_direcao_hora[gr]',\n",
    "            'vento_rajada_max_hora[m/s]',\n",
    "            'vento_vel_hora[m/s]',\n",
    "            ])\n",
    "    \n",
    "        return df\n",
    "            \n",
    "    except Exception as e:\n",
    "        \n",
    "        import inspect\n",
    "        print(f\"{inspect.getframeinfo(inspect.currentframe()).function};{e};{None}\")\n",
    "\n",
    "    finally:\n",
    "        \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dados_meteorologicos_dir = r'..\\data\\dados-meteorologicos'\n",
    "path_dados_meteorologicos_separados_dir = r\"..\\data\\dados_tratados\\dados_meteorologicos_separados\"\n",
    "\n",
    "list_path_files = listar_arquivos_originais(path_dados_meteorologicos_dir)\n",
    "\n",
    "df_dados_meteorologicos = pd.DataFrame(columns=[\n",
    "        'data_hora',\n",
    "        'estacao_cidade', \n",
    "        'uf',\n",
    "        'regiao', \n",
    "        'estacao_latitude', \n",
    "        'estacao_longitude', \n",
    "        'estacao_altitude',\n",
    "        'precip_total_horario[mm]',\n",
    "        'pres_atm_estacao_horaria[mB]',\n",
    "        'pres_atm_max_hora_ant[mB]',\n",
    "        'pres_atm_min_hora_ant[mB]',\n",
    "        'radiacao_global[KJ/m2]',\n",
    "        'temp_ar_bulbo_seco_horario[oC]',\n",
    "        'temp_ponto_orvalho[oC]',\n",
    "        'temp_max_hora_ant[oC]',\n",
    "        'temp_min_hora_ant[oC]',\n",
    "        'temp_orv_max_hora_ant[oC]',\n",
    "        'temp_orv_min_hora_ant[oC]',\n",
    "        'umid_relat_ar_max_hora_ant[%]',\n",
    "        'umid_relat_ar_min_hora_ant[%]',\n",
    "        'umid_relat_ar_hora_atual[%]',\n",
    "        'vento_direcao_hora[gr]',\n",
    "        'vento_rajada_max_hora[m/s]',\n",
    "        'vento_vel_hora[m/s]',\n",
    "        ])\n",
    "\n",
    "for path_dados_meteorologicos_file in list_path_files:\n",
    "\n",
    "    encoding = identificar_encoding(path_dados_meteorologicos_file)\n",
    "    # separar_dados_meteorologicos(path_dados_meteorologicos_file)\n",
    "    dados_geograficos = obter_dados_geograficos_estacao(path_dados_meteorologicos_file)\n",
    "    \n",
    "    path_dados_meteorologicos_separados_file = os.path.join(path_dados_meteorologicos_separados_dir, path_dados_meteorologicos_file.split('\\\\')[-1])\n",
    "    dados_meteorologicos = obter_dados_meteorologicos(path_dados_meteorologicos_separados_file, encoding)\n",
    "    df_file = integrar_dados_geograficos_meteorologicos(dados_meteorologicos, dados_geograficos)\n",
    "    df_dados_meteorologicos = pd.concat([df_dados_meteorologicos, df_file], ignore_index=True)\n",
    "\n",
    "df_dados_meteorologicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_meteorologicos.to_csv(r\"..\\data\\df_dados_meteorologicos.csv\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
